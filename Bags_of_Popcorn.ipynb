{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentimental analysis \n",
    "The competition from Kaggel \"*Bag of Words Meets Bags of Popcorn*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score\n",
    "\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you can download data from the page of competition https://www.kaggle.com/c/word2vec-nlp-tutorial/data\n",
    "\n",
    "imbd_train = pd.read_csv('data/labeledTrainData.tsv', delimiter='\\t')\n",
    "imbd_test = pd.read_csv('data/testData.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 3)\n",
      "(25000, 2)\n"
     ]
    }
   ],
   "source": [
    "# Number of the train and test datasets\n",
    "\n",
    "print(imbd_train.shape)\n",
    "print(imbd_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12500, 3)\n"
     ]
    }
   ],
   "source": [
    "# The training dataset consists balanced number of the positive and negative reviews\n",
    "\n",
    "print(imbd_train[imbd_train.sentiment == 1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_submission(prediction, file_index):\n",
    "    response = pd.DataFrame(data={'id': imbd_test.id, 'sentiment': prediction})\n",
    "    response.to_csv('submissions/{}.csv'.format(file_index), index=False)\n",
    "    \n",
    "    print('The submission is ready {}.csv'.format(file_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pipeline for finding the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\n",
    "        'feature_processing', FeatureUnion(transformer_list=[\n",
    "            ('words_processing', Pipeline([\n",
    "                ('tfidf', TfidfVectorizer()),\n",
    "            ])),\n",
    "            ('characters_processing', Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(analyzer='char')),\n",
    "            ]))\n",
    "        ])\n",
    "     ),\n",
    "    ('lr', LogisticRegression(n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'lr__C': (0.01, 0.1, 1, 10),\n",
    "    'lr__penalty': ('l1', 'l2'),\n",
    "    \n",
    "    'feature_processing__words_processing__tfidf__min_df': (0, 1, 3, 5, 8),\n",
    "    'feature_processing__words_processing__tfidf__ngram_range': ((1, 1), (1, 2), (1, 3)),\n",
    "    'feature_processing__words_processing__tfidf__max_features': (None, 9000, 12000, 14000),\n",
    "    \n",
    "    'feature_processing__characters_processing__tfidf__min_df': (0, 1, 3, 5, 8),\n",
    "    'feature_processing__characters_processing__tfidf__ngram_range': ((1, 1), (1, 2), (1, 3)),\n",
    "    'feature_processing__characters_processing__tfidf__max_features': (None, 500, 1000, 1500)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = cross_validation.StratifiedShuffleSplit(imbd_train.sentiment, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Submissions are judged on area under the ROC curve. \n",
    "\n",
    "grid = RandomizedSearchCV(pipeline, parameters, scoring='roc_auc', cv=cv, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 58min 21s, sys: 5min 9s, total: 2h 3min 30s\n",
      "Wall time: 2h\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedShuffleSplit(labels=[1 1 ..., 0 1], n_iter=10, test_size=0.3, random_state=42),\n",
       "          error_score='raise',\n",
       "          estimator=Pipeline(steps=[('feature_processing', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('words_processing', Pipeline(steps=[('selecting', ItemSelector(key='review')), ('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "          fit_params={}, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'feature_processing__words_processing__tfidf__max_features': (None, 9000, 12000, 14000), 'feature_processing__characters_processing__tfidf__ngram_range': ((1, 1), (1, 2), (1, 3)), 'feature_processing__words_processing__tfidf__ngram_range': ((1, 1), (1, 2), (1, 3)), 'feature_proc..., 1, 10), 'feature_processing__characters_processing__tfidf__max_features': (None, 500, 1000, 1500)},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "grid.fit(imbd_train.review, imbd_train.sentiment);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9585418808888888"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_processing__characters_processing__tfidf__max_features': 1000,\n",
       " 'feature_processing__characters_processing__tfidf__min_df': 8,\n",
       " 'feature_processing__characters_processing__tfidf__ngram_range': (1, 3),\n",
       " 'feature_processing__words_processing__tfidf__max_features': 14000,\n",
       " 'feature_processing__words_processing__tfidf__min_df': 5,\n",
       " 'feature_processing__words_processing__tfidf__ngram_range': (1, 3),\n",
       " 'lr__C': 10,\n",
       " 'lr__penalty': 'l2'}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set best parameters to the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline.set_params(\n",
    "    feature_processing__characters_processing__tfidf__max_features=1000,\n",
    "    feature_processing__characters_processing__tfidf__min_df=8,\n",
    "    feature_processing__characters_processing__tfidf__ngram_range=(1, 3),\n",
    "    feature_processing__words_processing__tfidf__max_features=14000,\n",
    "    feature_processing__words_processing__tfidf__min_df=5,\n",
    "    feature_processing__words_processing__tfidf__ngram_range=(1, 3),\n",
    "    lr__C=1,\n",
    "    lr__penalty='l2'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use cross_val_score for investigate final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.11 s, sys: 248 ms, total: 1.36 s\n",
      "Wall time: 2min 3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.95655167,  0.95327619,  0.95599876])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cross_val_score(pipeline, imbd_train.review, imbd_train.sentiment, scoring='roc_auc', cv=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 50s, sys: 9.14 s, total: 1min 59s\n",
      "Wall time: 1min 50s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('feature_processing', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('words_processing', Pipeline(steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1....ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipeline.fit(imbd_train.review, imbd_train.sentiment);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The submission is ready tfidf_lr_final.csv\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "prediction = pipeline.predict_proba(imbd_test.review)[:,1]\n",
    "make_submission(prediction, 'tfidf_lr_final')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The score for the _testing_ dataset is **0.95893**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis of the prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_important_features(feature_names, target_names, weights, n_top=30):\n",
    "    sorted_features_indices = weights[0].argsort()[::-1]\n",
    "    \n",
    "    print('The most important \"features\" (words) for the first class: \\n')\n",
    "    most_important = sorted_features_indices[:n_top]\n",
    "    print(\",\\n\".join(\"{0}: {1:.4f}\".format(feature_names[j], weights[0, j]) for j in most_important))\n",
    "\n",
    "    print('\\nThe most unimportant \"features\" (words) for the first class: \\n')\n",
    "    least_important = sorted_features_indices[-n_top:]\n",
    "    print(\",\\n\".join(\"{0}: {1:.4f}\".format(feature_names[j], weights[0, j]) for j in least_important))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most important \"features\" (words) for the first class: \n",
      "\n",
      "great: 17.1706,\n",
      "excellent: 14.1051,\n",
      "best: 12.3115,\n",
      "wonderful: 11.1220,\n",
      "perfect: 10.7192,\n",
      "amazing: 9.7274,\n",
      "love: 9.6657,\n",
      "favorite: 9.5664,\n",
      "fun: 9.1872,\n",
      "loved: 8.8379,\n",
      "today: 8.5322,\n",
      "enjoyed: 8.1083,\n",
      "brilliant: 8.0669,\n",
      "beautiful: 7.7421,\n",
      "superb: 7.7398,\n",
      "highly: 7.1639,\n",
      "enjoy: 6.9930,\n",
      "definitely: 6.9677,\n",
      "fantastic: 6.8260,\n",
      "enjoyable: 6.5264,\n",
      "10 10: 6.5148,\n",
      "job: 6.4521,\n",
      "bit: 6.3647,\n",
      "liked: 6.3429,\n",
      "life: 6.2765,\n",
      "especially: 6.2463,\n",
      "entertaining: 6.1633,\n",
      "heart: 6.0502,\n",
      "funniest: 6.0379,\n",
      "rare: 5.9032\n",
      "\n",
      "The most unimportant \"features\" (words) for the first class: \n",
      "\n",
      "badly: -7.2644,\n",
      "pointless: -7.3440,\n",
      "avoid: -7.6105,\n",
      "disappointing: -7.6699,\n",
      "just: -7.6744,\n",
      "save: -7.6953,\n",
      "lame: -7.8409,\n",
      "mess: -7.8716,\n",
      "waste time: -7.9765,\n",
      "fails: -8.0054,\n",
      "ridiculous: -8.2217,\n",
      "minutes: -8.3099,\n",
      "disappointment: -8.3445,\n",
      "annoying: -8.4698,\n",
      "instead: -8.5852,\n",
      "stupid: -8.6196,\n",
      "supposed: -8.7243,\n",
      "unfortunately: -8.9381,\n",
      "script: -9.1088,\n",
      "dull: -9.3347,\n",
      "poorly: -9.3483,\n",
      "horrible: -9.7118,\n",
      "terrible: -10.4718,\n",
      "worse: -11.1009,\n",
      "poor: -12.1545,\n",
      "waste: -13.0283,\n",
      "boring: -13.0838,\n",
      "awful: -14.3211,\n",
      "bad: -17.2290,\n",
      "worst: -19.8708\n"
     ]
    }
   ],
   "source": [
    "display_important_features(tfidf.get_feature_names(), imbd_train.sentiment.unique(), clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
